{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import of libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "# Definition of state class, to make flow control easier.\n",
    "# It stores what was done in the last frame\n",
    "# Init - When it is first frame\n",
    "# Det_full - last frame had succesfull full detection\n",
    "# Det_part - last frame had succesfull partial (based on previous lines) detection\n",
    "# No_det - When the detection was not succesfull in last frame\n",
    "# Need_full - On cases when next frame needs full detection (e.g. too many no detect frames)\n",
    "class State():\n",
    "    def __init__(self):\n",
    "        self.state = 'None'\n",
    "        self.cam = 'Init'\n",
    "        \n",
    "    def detected_full(self):\n",
    "        self.state = 'det_full'\n",
    "        \n",
    "    def detected_part(self):\n",
    "        self.state = 'det_part'\n",
    "        \n",
    "    def no_detect(self):\n",
    "        self.state = 'no_det'\n",
    "        \n",
    "    def need_full(self):\n",
    "        self.state = 'need_full'\n",
    "\n",
    "# Class to store previously detected lines\n",
    "# It stores both left and right lane values in single object\n",
    "# In the method add it does the majority of calculations:\n",
    "# - calculates delta from previous detections and if too large, then rejects the new detection\n",
    "# - averages (smoothes) polynomial values over multiple frames\n",
    "# - sets the class variables to be used in frame processing\n",
    "# - this inculdes curvature and off-center calculations\n",
    "# Method no_detect - sets variables when line was not detected\n",
    "# Method get_x_from_last - returns x values for Left and Right lane based on y value input\n",
    "\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_fitted = [] \n",
    "        self.recent_fitted_cr = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        #self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        #self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        self.current_fit_cr = [np.array([False])]\n",
    "        #radius of curvature of the line in some units\n",
    "        self.left_curverad = None\n",
    "        self.right_curverad = None\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        #self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        #self.ally = None\n",
    "        # how many frames without fit\n",
    "        self.frames_wo_detection = 0\n",
    "        #x,y values for detected line pixels on Left\n",
    "        self.lastLeft = None  \n",
    "        #x,y values for detected line pixels on Right\n",
    "        self.lastRight = None  \n",
    "        #difference too large\n",
    "        self.diff_error = False\n",
    "\n",
    "    def add(self, left, right, scan, left_fit_cr, right_fit_cr):\n",
    "        toAdd = True\n",
    "        \n",
    "        if (len(self.recent_fitted)>0 and (scan!='full')):\n",
    "            deltaL = abs(left[1]-self.recent_fitted[-1][0][1])\n",
    "            deltaR = abs(right[1]-self.recent_fitted[-1][1][1])\n",
    "            self.diffs = (deltaL, deltaR)\n",
    "            if (deltaL>1.0 or deltaR>1.0):\n",
    "                toAdd = False\n",
    "            \n",
    "        if (toAdd):\n",
    "            #Adding weighted\n",
    "            cnt = len(self.recent_fitted)\n",
    "            if (cnt>0):\n",
    "                lim = min(cnt, 7) # limit how far to look back\n",
    "                left_last = self.recent_fitted[-1][0]\n",
    "                right_last = self.recent_fitted[-1][1]\n",
    "                left_avg = (left_last*lim+left)/(lim+1)\n",
    "                right_avg = (right_last*lim+right)/(lim+1)\n",
    "                self.recent_fitted.append([left_avg, right_avg])\n",
    "                # same for metres\n",
    "                left_last_cr = self.recent_fitted_cr[-1][0]\n",
    "                right_last_cr = self.recent_fitted_cr[-1][1]\n",
    "                left_avg_cr = (left_last_cr*lim+left_fit_cr)/(lim+1)\n",
    "                right_avg_cr = (right_last_cr*lim+right_fit_cr)/(lim+1)\n",
    "                self.recent_fitted_cr.append([left_avg_cr, right_avg_cr])\n",
    "\n",
    "            else:\n",
    "                self.recent_fitted.append([left, right])\n",
    "                self.recent_fitted_cr.append([left_fit_cr, right_fit_cr])\n",
    "            \n",
    "            #self.recent_fitted.append([left, right])\n",
    "            self.current_fit=self.recent_fitted[-1]\n",
    "            self.current_fit_cr=self.recent_fitted_cr[-1]\n",
    "            \n",
    "            #calculate curvature\n",
    "            y_eval=720\n",
    "            ym_per_pix = 12/280 # meters per pixel in y dimension\n",
    "            xm_per_pix = 3.7/630 # meters per pixel in x dimension\n",
    "\n",
    "            self.left_curverad = ((1 + (2*self.current_fit_cr[0][0]*y_eval*ym_per_pix + self.current_fit_cr[0][1])**2)**1.5) / np.absolute(2*self.current_fit_cr[0][0])\n",
    "            self.right_curverad = ((1 + (2*self.current_fit_cr[1][0]*y_eval*ym_per_pix + self.current_fit_cr[1][1])**2)**1.5) / np.absolute(2*self.current_fit_cr[1][0])\n",
    "            \n",
    "            self.radius_of_curvature = (self.left_curverad + self.right_curverad)/2\n",
    "            # get off center position\n",
    "            scr_middle_pix = int(1280/2)\n",
    "            l,r = self.get_x_from_last(y_eval)\n",
    "            line_middle_pix = int((r+l)/2)\n",
    "            car_scr_offset_px = scr_middle_pix-line_middle_pix\n",
    "            \n",
    "            self.line_base_pos = car_scr_offset_px*xm_per_pix\n",
    "            \n",
    "            self.detected = True\n",
    "            self.frames_wo_detection = 0\n",
    "            self.diff_error = False\n",
    "        else:\n",
    "            self.diff_error = True\n",
    "            self.detected = False\n",
    "            self.frames_wo_detection +=1\n",
    "\n",
    "    def no_detect(self):\n",
    "        self.detected = False\n",
    "        self.frames_wo_detection +=1\n",
    "    def get_x_from_last(self, y):\n",
    "        xL = self.current_fit[0][0]*y**2 + self.current_fit[0][1]*y + self.current_fit[0][2]\n",
    "        xR = self.current_fit[1][0]*y**2 + self.current_fit[1][1]*y + self.current_fit[1][2]\n",
    "        return xL, xR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_camera():\n",
    "    # calibrate camera \n",
    "    # load data, but if error then recalculate and save\n",
    "    try:\n",
    "        data = pickle.load(open('calibration.pkl', 'rb'))\n",
    "        mtx = data[0]\n",
    "        dist = data[1]\n",
    "        #print ('Camera calibration read from file - OK')\n",
    "    except:\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        objp = np.zeros((6*9,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # x,y coords, (0,0,0)...(8,5,0)\n",
    "        suc_cal_img = 0\n",
    "        for i in range (1,21):\n",
    "            cal_img_name = 'camera_cal/calibration'+str(i)+'.jpg'\n",
    "            cal_img = cv2.imread(cal_img_name,1)\n",
    "            cal_img_gray = cv2.cvtColor(cal_img, cv2.COLOR_BGR2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(cal_img_gray, (9,6),None)\n",
    "            if ret == True:\n",
    "                imgpoints.append(corners)\n",
    "                objpoints.append(objp)\n",
    "                suc_cal_img += 1\n",
    "        #print ('Succesfully read # calibration images:' + str(suc_cal_img))\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, cal_img_gray.shape[::-1],None,None)\n",
    "        data = [mtx,dist]\n",
    "        pickle.dump(data, open('calibration.pkl', 'wb'))\n",
    "        #print ('Camera calibration saved to file - OK')\n",
    "    return mtx, dist\n",
    "\n",
    "def undistort(image, mtx, dist):\n",
    "    undistort_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    return undistort_img\n",
    "\n",
    "mtx, dist = cal_camera()\n",
    "sample_img = cv2.imread('camera_cal/calibration1.jpg',1)\n",
    "sample_undistort_img = undistort(sample_img, mtx, dist)\n",
    "_ = cv2.imwrite('output_images/undistorted_calibration1.jpg', sample_undistort_img)\n",
    "\n",
    "sample_img = cv2.imread('test_images/test1.jpg',1)\n",
    "sample_undistort_img = undistort(sample_img, mtx, dist)\n",
    "_ = cv2.imwrite('output_images/undistorted_test1.jpg', sample_undistort_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_white_adaptive(img, yChan=200):\n",
    "    conv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    lower_wht = np.array([yChan,0,0]) # 200,0,0\n",
    "    upper_wht = np.array([255,255,255]) # 255,255,255\n",
    "    mask_white = cv2.inRange(conv, lower_wht, upper_wht)\n",
    "    return mask_white\n",
    "\n",
    "def mask_hls(img, thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s = hls[:,:,2]\n",
    "    retval, binary = cv2.threshold(s.astype('uint8'), thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def mask_sob_mag(img, kernel=3, thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel)\n",
    "    magGrad = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scale = np.max(magGrad)/255 \n",
    "    magGrad = (magGrad/scale).astype(np.uint8) \n",
    "    ret, binary = cv2.threshold(magGrad, thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def mask_gray(image, thresh_min=180): # Not used in current pipeline\n",
    "    gray = image[:,:,0]\n",
    "    #plt.imshow(gray, cmap='gray')\n",
    "    thresh_max = 255\n",
    "    binary = np.zeros_like(gray)\n",
    "    binary[(gray >= thresh_min) & (gray <= thresh_max)] = 1\n",
    "    return binary\n",
    "\n",
    "def mask_yell(img): # Not used in current pipeline\n",
    "    conv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    lower_yel = np.array([0,40,100]) # 0,40,100\n",
    "    upper_yel = np.array([100,255,250]) # 100,255,250\n",
    "    mask_yellow = cv2.inRange(conv, lower_yel, upper_yel)\n",
    "    return mask_yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This matrix is used for initial frames only, \n",
    "# After lines are detected, then \n",
    "def calc_transf():\n",
    "    dist_src = np.float32([[585,460],[695,460],[1127,720],[203,720]])\n",
    "    dist_dst = np.float32([[320,0],[960,0],[960,720],[320,720]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(dist_src, dist_dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dist_dst, dist_src)\n",
    "    return M, Minv\n",
    "\n",
    "def warp(image, M):\n",
    "    warped = cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "def warp_debug(image, M):\n",
    "    img_deb = image.copy()\n",
    "    warped_deb = cv2.warpPerspective(img_deb, M, (img_deb.shape[1], img_deb.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    pts1 = np.array([[585,460],[695,460],[1127,720],[203,720]], np.int32)\n",
    "    #pts1 = pts1.reshape((-1,1,2))\n",
    "    cv2.polylines(img_deb, [pts1], True, (255,0,0), 3)\n",
    "    pts2 = np.array([[320,0],[960,0],[960,720],[320,720]], np.int32)\n",
    "    #pts2 = pts2.reshape((-1,1,2)) \n",
    "    cv2.polylines(warped_deb, [pts2], True, (255,0,0), 3)\n",
    "    return warped_deb, img_deb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_points(img, height, mainPeak, searchRange):\n",
    "    points = []\n",
    "    prevPeak = mainPeak\n",
    "    num_rows = int(img.shape[0]/height)\n",
    "    for row in range(num_rows,-1,-1):\n",
    "        startPos = max(prevPeak-searchRange, 0)\n",
    "        endPos = min(prevPeak+searchRange, img.shape[1])\n",
    "        mid_vert_pix = int(row*height+height/2)\n",
    "        hist = np.sum(img[(row*height):(row+1)*height,startPos:endPos], axis=0, dtype=np.int32)\n",
    "        #detMaxs = signal.find_peaks_cwt(hist, np.arange(1,10))\n",
    "        detMaxs = np.argmax(hist)\n",
    "        histRev = hist[::-1] # check reverse histogram to find if there are multiple maximum peaks\n",
    "        detMaxRev = len(histRev) - np.argmax(histRev) #argmax returns first index, this line returns last\n",
    "        if (detMaxs==0 and hist[0]==hist[-1]):\n",
    "            detMaxs = float('NaN')\n",
    "        #if len(detMaxs)>0:\n",
    "        if (detMaxs==detMaxs):\n",
    "            #detMaxs = int(detMaxs)\n",
    "            detMaxs = int((detMaxs + detMaxRev)/2) # With multiple max peak averaging (first+last)/2\n",
    "            prevPeak = 0+startPos+detMaxs\n",
    "            points.append((mid_vert_pix, prevPeak))\n",
    "        else:\n",
    "            pass #TBD if no max found, search for different value\n",
    "        \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_peaks_full(img, height=20):\n",
    "    midP = int(img.shape[1]/2)\n",
    "    # Check peak = np.argmax(histogram)\n",
    "    leftH = np.sum(img[480:,:midP], axis=0, dtype=np.int32)\n",
    "    rightH = np.sum(img[480:,midP:], axis=0, dtype=np.int32)\n",
    "    mainPeakL = np.argmax(leftH)\n",
    "    #mainPeakL = signal.find_peaks_cwt(leftH, (np.arange(4,16)))\n",
    "    #print (mainPeakL)\n",
    "    mainPeakR = np.argmax(rightH)+midP\n",
    "    \n",
    "    #mainPeakR = np.add(signal.find_peaks_cwt(rightH, np.arange(4,16)),midP)\n",
    "    #print (mainPeakR)\n",
    "    if (mainPeakL==mainPeakL):\n",
    "        left_pts = find_points(img, height, mainPeakL, 80)\n",
    "        mainPeakL = int(np.mean(mainPeakL))\n",
    "    else:\n",
    "        left_pts = np.empty( shape=(0, 0) )\n",
    "\n",
    "    if (mainPeakR==mainPeakR):\n",
    "        right_pts = find_points(img, height, mainPeakR, 80)\n",
    "        mainPeakR = int(np.mean(mainPeakR))\n",
    "    else:\n",
    "        right_pts = np.empty( shape=(0, 0) )\n",
    "    \n",
    "    return left_pts, right_pts, mainPeakL, mainPeakR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_points_part(img, height, searchRange, side):\n",
    "    points = []\n",
    "    num_rows = int(img.shape[0]/height)\n",
    "    for row in range(num_rows,-1,-1):\n",
    "        mid_vert_pix = int(row*height+height/2)\n",
    "        \n",
    "        if (side=='L'):\n",
    "            prevPeak=line.get_x_from_last(mid_vert_pix)[0]\n",
    "        else:\n",
    "            prevPeak=line.get_x_from_last(mid_vert_pix)[1]\n",
    "        \n",
    "        startPos = max(prevPeak-searchRange, 0)\n",
    "        endPos = min(prevPeak+searchRange, img.shape[1])\n",
    "        if (startPos>=endPos):\n",
    "            line.no_detect()\n",
    "            break\n",
    "            \n",
    "        hist = np.sum(img[(row*height):(row+1)*height,startPos:endPos], axis=0, dtype=np.int32)\n",
    "        #detMaxs = signal.find_peaks_cwt(hist, np.arange(1,10))\n",
    "        detMaxs = np.argmax(hist)\n",
    "        histRev = hist[::-1] # check reverse histogram to find if there are multiple maximum peaks\n",
    "        detMaxRev = len(histRev) - np.argmax(histRev) #argmax returns first index, this line returns last\n",
    "        if (detMaxs==0 and hist[0]==hist[-1]):\n",
    "            detMaxs = float('NaN')\n",
    "        #if len(detMaxs)>0:\n",
    "        if (detMaxs==detMaxs):\n",
    "            #detMaxs = int(detMaxs)\n",
    "            detMaxs = int((detMaxs + detMaxRev)/2) # With multiple max peak averaging (first+last)/2\n",
    "            prevPeak = 0+startPos+detMaxs\n",
    "            points.append((mid_vert_pix, prevPeak))\n",
    "        else:\n",
    "            pass #TBD if no max found, search for different value\n",
    "#            print (row)\n",
    "#            print (side)\n",
    "#            print (line.current_fit)\n",
    "#            print (startPos, endPos)\n",
    "#            print (hist)\n",
    "        \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_peaks_partial(img, height=20):\n",
    "    left_pts = find_points_part(img, height, 40, 'L')\n",
    "    right_pts = find_points_part(img, height, 40, 'R')\n",
    "    mainPeakL, mainPeakR = line.get_x_from_last(img.shape[1])\n",
    "    \n",
    "    return left_pts, right_pts, mainPeakL, mainPeakR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_frame(image, debug='None', name='noname'):\n",
    "    # get current state of detection to decide on actions to process\n",
    "    # 'None', 'det_full', 'det_part', 'no_det'  \n",
    "    curr_state = st.state\n",
    "    # get distortion and warp matrix\n",
    "    mtx, dist = cal_camera()\n",
    "    M, Minv = calc_transf()\n",
    "    \n",
    "    # undistort input image\n",
    "    undistort_img = undistort(image, mtx, dist)\n",
    "       \n",
    "    # apply masks and get binary output\n",
    "    magthr = mask_sob_mag(undistort_img, kernel=9, thresh=(50, 250))\n",
    "    hls = mask_hls(undistort_img, thresh=(88, 190))\n",
    "    white = mask_white_adaptive(undistort_img)\n",
    "    \n",
    "    combined_mask = np.zeros_like(magthr)\n",
    "    combined_mask[(magthr > 0) | (hls > 0) | (white > 0)] = 1    \n",
    "    binary = warp(combined_mask, M)\n",
    "    \n",
    "    # warped undistorted used for debugging, binary used in pipeline\n",
    "    warped = warp(undistort_img, M) \n",
    "    warp_deb, img_deb = warp_debug(undistort_img, M)\n",
    "        \n",
    "    \n",
    "    if (debug=='Save'):\n",
    "        combined_mask = np.uint8(255*combined_mask/np.max(combined_mask))\n",
    "        binary = np.uint8(255*binary/np.max(binary))\n",
    "        _ = cv2.imwrite('output_images/01original_'+name+'.jpg', image)\n",
    "        _ = cv2.imwrite('output_images/02undistorted_'+name+'.jpg', undistort_img)\n",
    "        _ = cv2.imwrite('output_images/03sobel_magnitude_'+name+'.jpg', magthr)\n",
    "        _ = cv2.imwrite('output_images/04hls_s_'+name+'.jpg', hls)\n",
    "        _ = cv2.imwrite('output_images/05white_yuv_'+name+'.jpg', white)\n",
    "        _ = cv2.imwrite('output_images/06combined_mask_'+name+'.jpg', combined_mask)\n",
    "        _ = cv2.imwrite('output_images/09warped_mask_'+name+'.jpg', binary)\n",
    "        _ = cv2.imwrite('output_images/p0persp_transf_orig_'+name+'.jpg', img_deb)\n",
    "        _ = cv2.imwrite('output_images/p1persp_transf_warped_'+name+'.jpg', warp_deb)\n",
    "    \n",
    "    # get line points\n",
    "    left_pts = np.empty(shape=(0,0))\n",
    "    right_pts = np.empty(shape=(0,0))\n",
    "    deb_text = ''\n",
    "    scan = ''\n",
    "    \n",
    "    if (curr_state=='det_full' or curr_state=='det_part'):\n",
    "        # Detected on previous frame\n",
    "        # This frame: detect partial based on previous full frame\n",
    "        left_pts, right_pts, mainPeakL, mainPeakR = get_peaks_partial(binary)\n",
    "        left_pts = np.array(left_pts, dtype=np.int32)\n",
    "        right_pts = np.array(right_pts, dtype=np.int32)\n",
    "        scan = 'part'\n",
    "        if (left_pts.shape[0]>0 and right_pts.shape[0]>0):\n",
    "            deb_text = 'Partial, detected L:' + str(len(left_pts))+' | R:' +str(len(right_pts))\n",
    "            st.detected_part()\n",
    "            line.lastLeft=left_pts\n",
    "            line.lastRight=right_pts\n",
    "        else:\n",
    "            deb_text = 'Partial, not detected!'\n",
    "            line.no_detect()\n",
    "            st.no_detect()\n",
    "            left_pts = line.lastLeft\n",
    "            right_pts = line.lastRight\n",
    "\n",
    "    elif (curr_state=='no_det'):\n",
    "        # Did not detect in previous frame\n",
    "        # Deciding to detect partial or full\n",
    "        \n",
    "        if (line.frames_wo_detection<=10):\n",
    "            left_pts, right_pts, mainPeakL, mainPeakR = get_peaks_partial(binary)\n",
    "            left_pts = np.array(left_pts, dtype=np.int32)\n",
    "            right_pts = np.array(right_pts, dtype=np.int32)\n",
    "            deb_text = 'noDet - Part, detected L:' + str(len(left_pts))+' | R:' +str(len(right_pts))\n",
    "            scan = 'part'\n",
    "            if (left_pts.shape[0]>0 and right_pts.shape[0]>0):\n",
    "                deb_text = 'Partial after not detected, detected L:' + str(len(left_pts))+' | R:' +str(len(right_pts))\n",
    "                st.detected_part()\n",
    "                line.lastLeft=left_pts\n",
    "                line.lastRight=right_pts\n",
    "            else:\n",
    "                deb_text = 'Partial after not detected, not detected! #:' + str(line.frames_wo_detection)\n",
    "                line.no_detect()\n",
    "                st.no_detect()\n",
    "                left_pts = line.lastLeft\n",
    "                right_pts = line.lastRight\n",
    "\n",
    "\n",
    "        else:\n",
    "            left_pts, right_pts, mainPeakL, mainPeakR = get_peaks_full(binary)\n",
    "            left_pts = np.array(left_pts, dtype=np.int32)\n",
    "            right_pts = np.array(right_pts, dtype=np.int32)\n",
    "            scan = 'full'\n",
    "            if (left_pts.shape[0]>0 and right_pts.shape[0]>0):\n",
    "                deb_text = 'Full  after not detected, detected L:' + str(len(left_pts))+' | R:' +str(len(right_pts))\n",
    "                st.detected_full()\n",
    "                line.lastLeft=left_pts\n",
    "                line.lastRight=right_pts\n",
    "            else:\n",
    "                deb_text = 'Full after not detected, not detected! #:' + str(line.frames_wo_detection)\n",
    "                line.no_detect()\n",
    "                st.need_full()\n",
    "    else:\n",
    "        # Initial detection, need full or unknown state - full detection\n",
    "        left_pts, right_pts, mainPeakL, mainPeakR = get_peaks_full(binary)\n",
    "        left_pts = np.array(left_pts, dtype=np.int32)\n",
    "        right_pts = np.array(right_pts, dtype=np.int32)\n",
    "        scan = 'full'\n",
    "        if (left_pts.shape[0]>0 and right_pts.shape[0]>0):\n",
    "            deb_text = 'Full, detected L:' + str(len(left_pts))+' | R:' +str(len(right_pts))\n",
    "            st.detected_full()\n",
    "            line.lastLeft=left_pts\n",
    "            line.lastRight=right_pts\n",
    "        else:\n",
    "            deb_text = 'Full, not detected!'\n",
    "            line.no_detect()\n",
    "            #st.no_detect()\n",
    "    \n",
    "    \n",
    "    # as output we need left_pts and right_pts in any case\n",
    "    drawing = np.zeros_like(warped)\n",
    "    \n",
    "    # Draw diagnostic lines and points\n",
    "    try:\n",
    "        if (mainPeakL==mainPeakL):\n",
    "            cv2.line(drawing, (mainPeakL, 600), (mainPeakL, 720), (0,255,255), thickness=4)\n",
    "        if (mainPeakR==mainPeakR):\n",
    "            cv2.line(drawing, (mainPeakR, 600), (mainPeakR, 720), (0,255,255), thickness=4)\n",
    "    except:\n",
    "        pass\n",
    "    peak = drawing.copy()\n",
    "    # Calculate lines from points\n",
    "    y_eval = np.max(720)\n",
    "    yvals = np.linspace(0, 100, num=101)*7.2\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 12/280 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/630 # meters per pixel in x dimension\n",
    "\n",
    "    \n",
    "    \n",
    "    if (left_pts.shape[0]>0 and right_pts.shape[0]>0):\n",
    "        leftTtB = left_pts[::-1]\n",
    "        yvalsx = leftTtB[:,0]\n",
    "        leftx = leftTtB[:,1]\n",
    "        left_fit = np.polyfit(yvalsx, leftx, 2)\n",
    "\n",
    "        rightTtB = right_pts[::-1]\n",
    "        yvalsy = rightTtB[:,0]\n",
    "        rightx = rightTtB[:,1]\n",
    "        right_fit = np.polyfit(yvalsy, rightx, 2)\n",
    "\n",
    "        l_x = left_fit[0]*yvals**2 + left_fit[1]*yvals + left_fit[2]\n",
    "        pts_left = np.array([np.transpose(np.vstack([l_x, yvals]))])\n",
    "\n",
    "        r_x = right_fit[0]*yvals**2 + right_fit[1]*yvals + right_fit[2]\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([r_x, yvals])))])\n",
    "\n",
    "        left_fit_cr = np.polyfit(yvalsx*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(yvalsy*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        #left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        #right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "    if (st.state == 'det_full' or st.state == 'det_part'):\n",
    "        line.add(left_fit, right_fit, scan, left_fit_cr, right_fit_cr)\n",
    "        if (st.cam == 'Init'):\n",
    "            st.cam = 'Calc'\n",
    "\n",
    "    # Drawing results on road image\n",
    "   \n",
    "    # Points that has been detected in frame\n",
    "    if (debug=='Save'):\n",
    "        _ = cv2.imwrite('output_images/14mid_lines_'+name+'.jpg', drawing)\n",
    "\n",
    "    for i in range(len(left_pts)):\n",
    "        cv2.circle(drawing, (left_pts[i,1],left_pts[i,0]), 2, (255, 0, 0), thickness=4)\n",
    "        cv2.circle(drawing, (left_pts[i,1],left_pts[i,0]), 4, (255, 0, 0), thickness=4)\n",
    "    for i in range(len(right_pts)):\n",
    "        cv2.circle(drawing, (right_pts[i,1],right_pts[i,0]), 2, (255, 0, 0), thickness=4)\n",
    "        cv2.circle(drawing, (right_pts[i,1],right_pts[i,0]),4, (255, 0, 0), thickness=4)\n",
    "    \n",
    "    points = drawing.copy()\n",
    "    if (debug=='Save'):\n",
    "        _ = cv2.imwrite('output_images/15points_'+name+'.jpg', drawing)\n",
    "\n",
    "    if (left_pts.shape[0]>0 and right_pts.shape[0]>0):\n",
    "        cv2.polylines(drawing, np.int_([pts_left]), False, (0,0,255), 3)\n",
    "        cv2.polylines(drawing, np.int_([pts_right]), False, (0,0,255), 3)\n",
    "    \n",
    "    polylines = drawing.copy()\n",
    "    if (debug=='Save'):\n",
    "        _ = cv2.imwrite('output_images/16polylines_'+name+'.jpg', drawing)\n",
    "\n",
    "        \n",
    "    # Draw filled polygon\n",
    "    if (left_pts.shape[0]>0 and right_pts.shape[0]>0):\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        cv2.fillPoly(drawing, np.int_([pts]), (0,255, 0))\n",
    "       \n",
    "    # Reverse prespective transform of the detected information\n",
    "    drawing2 = cv2.warpPerspective(drawing, Minv, (drawing.shape[1], drawing.shape[0]))\n",
    "    # Adding detection result on top of undistorted image\n",
    "    result = cv2.addWeighted(undistort_img, 1, drawing2, 0.3, 0)\n",
    "    \n",
    "    if (debug=='Save'):\n",
    "        _ = cv2.imwrite('output_images/20plotted_'+name+'.jpg', drawing)\n",
    "        _ = cv2.imwrite('output_images/21plotted_unwarp_'+name+'.jpg', drawing2)\n",
    "        _ = cv2.imwrite('output_images/22result_'+name+'.jpg', result)\n",
    "\n",
    "   \n",
    "    # Start of Additional text information    \n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "#    cv2.putText(result, 'Diff:'+str(line.diffs), (40,40), font, .5,(255,255,255),2,cv2.LINE_AA)\n",
    "#    if (line.frames_wo_detection>0):\n",
    "#        cv2.putText(result, 'NoDet:'+str(line.frames_wo_detection), (40,80), font, .5,(255,255,255),2,cv2.LINE_AA)\n",
    "#    cv2.putText(result, deb_text, (40,120), font, .5,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    #Curvature\n",
    "    if (st.state == 'det_full' or st.state == 'det_part'):\n",
    "        curvature = int((line.left_curverad + line.right_curverad) / 2)\n",
    "    else:\n",
    "        curvature = 0\n",
    "    if (curvature<4000):\n",
    "        cv2.putText(result, 'Curvature:'+str(curvature)+'m', (40,40), font, .5,(255,255,255),2,cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(result, 'Curvature: straight', (40,40), font, .5,(255,255,255),2,cv2.LINE_AA)\n",
    "    #cv2.putText(result, 'Left:'+str(line.left_curverad) + '   Right:'+str(line.right_curverad), (40,200), font, .5,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    # Offcenter\n",
    "    if (st.state == 'det_full' or st.state == 'det_part'):\n",
    "        car_pos = int(line.line_base_pos*100)\n",
    "    else:\n",
    "        car_pos = 0\n",
    "    if (car_pos<0):\n",
    "        cv2.putText(result, 'Distance from center:'+str(abs(car_pos))+'cm Left', (40,80), font, .5,(255,255,255),2,cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(result, 'Distance from center:'+str(abs(car_pos))+'cm Right', (40,80), font, .5,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    # End of Additional text information\n",
    "\n",
    "    \n",
    "    \n",
    "    if (debug=='Save'):\n",
    "        _ = cv2.imwrite('output_images/23result_text'+name+'.jpg', result)\n",
    "    \n",
    "    \n",
    "    # ------------- Diagnostics -------------------\n",
    "    #diag = True\n",
    "    \n",
    "    # middle panel text example\n",
    "    # using cv2 for drawing text in diagnostic pipeline.\n",
    "    if (debug=='Debug1'):\n",
    "        combined_mask = cv2.cvtColor(np.uint8(255*combined_mask/np.max(combined_mask)), cv2.COLOR_GRAY2RGB)\n",
    "        binary = cv2.cvtColor(np.uint8(255*binary/np.max(binary)), cv2.COLOR_GRAY2RGB)\n",
    "        magthr = cv2.cvtColor(magthr, cv2.COLOR_GRAY2RGB)\n",
    "        white = cv2.cvtColor(white, cv2.COLOR_GRAY2RGB)\n",
    "        hls = cv2.cvtColor(hls, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        diagScreen = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "        diagScreen[0:360, 0:640] = cv2.resize(image, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[0:360, 640:1280] = cv2.resize(undistort_img, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[0:360, 1280:1920] = cv2.resize(result, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[360:720, 0:640] = cv2.resize(magthr, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[360:720, 640:1280] = cv2.resize(white, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[360:720, 1280:1920] = cv2.resize(drawing2, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[720:1080, 0:640] = cv2.resize(hls, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[720:1080, 640:1280] = cv2.resize(combined_mask, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[720:1080, 1280:1920] = cv2.resize(binary, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        return diagScreen\n",
    "\n",
    "    if (debug=='Debug2'):\n",
    "        binary = cv2.cvtColor(np.uint8(255*binary/np.max(binary)), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        diagScreen = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "        diagScreen[0:360, 0:640] = cv2.resize(image, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[0:360, 640:1280] = cv2.resize(result, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[0:360, 1280:1920] = cv2.resize(img_deb, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[360:720, 0:640] = cv2.resize(warped, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[360:720, 640:1280] = cv2.resize(binary, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[360:720, 1280:1920] = cv2.resize(warp_deb, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[720:1080, 0:640] = cv2.resize(points, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[720:1080, 640:1280] = cv2.resize(polylines, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        diagScreen[720:1080, 1280:1920] = cv2.resize(drawing, (640,360), interpolation=cv2.INTER_AREA) \n",
    "        return diagScreen\n",
    "\n",
    "    \n",
    "    #font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    #middlepanel = np.zeros((120, 1280, 3), dtype=np.uint8)\n",
    "    #cv2.putText(middlepanel, 'Estimated lane curvature: ERROR!', (30, 60), font, 1, (255,0,0), 2)\n",
    "   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Generate examples of the test pipeline\n",
    "st = State()\n",
    "line = Line()\n",
    "image = cv2.imread('test_images/test2.jpg',1)\n",
    "result = process_frame(image, debug='Save', name='test')\n",
    "\n",
    "#Generate examples of the straight road\n",
    "st = State()\n",
    "line = Line()\n",
    "image = cv2.imread('test_images/straight_lines1.jpg',1)\n",
    "result = process_frame(image, debug='Save', name='straight1')\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video out_project_video.mp4\n",
      "[MoviePy] Writing video out_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [02:42<00:00,  7.95it/s]    | 1/1261 [00:00<02:47,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: out_project_video.mp4 \n",
      "\n",
      "CPU times: user 4min 30s, sys: 5 s, total: 4min 35s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "# Generate project video\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "st = State()\n",
    "line = Line()\n",
    "white_output = 'out_project_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_frame)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video out_project_video_debug1.mp4\n",
      "[MoviePy] Writing video out_project_video_debug1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [03:25<00:00,  6.63it/s]    | 1/1261 [00:00<03:22,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: out_project_video_debug1.mp4 \n",
      "\n",
      "CPU times: user 5min 56s, sys: 3.67 s, total: 5min 59s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "def process_frame_d1(image):\n",
    "    result = process_frame(image, debug='Debug1')\n",
    "    return result\n",
    "\n",
    "# Generate project video - debugging 1\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "st = State()\n",
    "line = Line()\n",
    "white_output = 'out_project_video_debug1.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_frame_d1)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video out_project_video_debug2.mp4\n",
      "[MoviePy] Writing video out_project_video_debug2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [03:06<00:00,  6.56it/s]    | 1/1261 [00:00<02:50,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: out_project_video_debug2.mp4 \n",
      "\n",
      "CPU times: user 5min 25s, sys: 5.71 s, total: 5min 30s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "def process_frame_d2(image):\n",
    "    result = process_frame(image, debug='Debug2')\n",
    "    return result\n",
    "\n",
    "# Generate project video - debugging 2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "st = State()\n",
    "line = Line()\n",
    "white_output = 'out_project_video_debug2.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_frame_d2)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:opencv]",
   "language": "python",
   "name": "conda-env-opencv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
